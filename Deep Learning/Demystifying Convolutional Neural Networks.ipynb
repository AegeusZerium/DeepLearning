{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demystifying Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article we will concretely explain how a Convolutional Neural Network works and how different it is from a regular Artificial Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://image.slidesharecdn.com/nvidiaces2015presentationdeck-150105190022-conversion-gate02/95/visual-computing-the-road-ahead-nvidia-ceo-jenhsun-huang-at-ces-2015-30-638.jpg?cb=1424436369)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, a [**Convolutional Neural Network**](https://en.wikipedia.org/wiki/Convolutional_neural_network) is a Deep learning model or a multilayered percepteron similar to Artificial Neural Networks which is most commonly applied to analyzing visual imagery.\n",
    "The founding father of Convolutional Neural Networks is the well known computer scientist working in Facebook [**Yann LeCun**](https://en.wikipedia.org/wiki/Yann_LeCun) who was the first one to use them to solve the hand written digits problem using the famous [**MNIST**](http://yann.lecun.com/exdb/mnist/) Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-0.journaldunet.com/XPrXteY4uHzxXounKVbjhBCh0aQ=/250x/smart/0744f6823657461ebd47a7af55f79a6c/ccmcms-jdn/10823697.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Neural_pathway_diagram.svg/512px-Neural_pathway_diagram.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://slideplayer.com/10833762/39/images/7/Computer+Vision+What+we+see+What+a+computer+sees.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we can't possibly talk about any type of Neural Networks without mentioning a little bit of neuroscience and how the human body (especially the brain) and its functions have been the primary inspiration for the creation of various Deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture of ConvNets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.lirmm.fr/~chaumont/images/CNN_ElectronicImaging2016.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the illustration above a ConvNet architecture is very similar to the regular ANN architecture especially in the last layers of the network namely the Fully connected layers area, you will also notice that a ConvNet accepts a volume as an input instead of a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now explore the layers that constitute a ConvNet and the mathematical operations that the latter goes through to visualize and classify pictures based on the features and attributes it has learnt during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input layer is mostly an n × m × 3 RGB (short for Red, Green and Blue) image(s) unlike an Artificial Neural Networks which gets fed with a n × 1 vector, nothing hard to grasp here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.sai-tai.com/blog/wp-content/uploads/2017/04/cross-section.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **Convolution layer** we compute the output of the dot product between an area of the input image(s) and a weight matrice called a **filter**, the filter will slide through out the whole image repeating the same dot product operation.  Two things that should be mentioned: \n",
    "- The filter must have the same number of channels as the input image.\n",
    "- it's commonly known that the deeper you go into the Network the more filters you use, the intuition behind it is that the more filters we have the more edge and feature detection you'll get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/2000/1*wqZ0Q4mBaHKjqWx45GPIow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the dimensions of the output of the Convolution layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Output Width:*** $$ \\frac{W - F_w + 2P}{S} + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Output Height:*** $$ \\frac{H - F_h + 2P}{S} + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- $W$: the width of the input image\n",
    "- $H$: the height of the input image\n",
    "- $F_{w}$: the width of the filter or kernel\n",
    "- $F_{h}$: the height of the filter\n",
    "- $P$: padding\n",
    "- $S$: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of channels of the Convolution layer output equals to the **number of filters** used during the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Convolutions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are probably asking yourself, why do we use convolutions in the first place ? why not flatten the input images from the beginning ? well if we do that we will end up with a massive number of parameters that need to be trained and most of us don't have the computational power that will solve our computationally expensive task in the fastest way possible.\n",
    "In addition, with the fewer parameters that the ConvNets have we can avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two widely used types of pooling, average pooling and max pooling where the latter being the most used of the two.\n",
    "The pooling layer is used to reduce the spatial dimensions, but not depth, on a convolutional neural network.\n",
    "When using the max pooling layer we take the highest number (the most responsive area in the image) of the input's area (an n × m matrice), whereas when we use the average pooling layer we take the mean of the input area instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://shafeentejani.github.io/assets/images/pooling.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Pooling ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the core goals of the pooling layer (max pooling in this case) is to provide spatial variance, which simply means that you or the machine will be capable of recognizing an object as an object even when its appearance varies in some way.\n",
    "for more in depth explanation of the pooling layer check this rigourous [**paper**](http://yann.lecun.org/exdb/publis/pdf/boureau-icml-10.pdf) by Yann LeCunn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linearity Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Non-linearity layer we use the ReLU activation function most if not all the time instead of the Sigmoid or Tan-H activation function.\n",
    "The ReLU activation function returns 0 for every negative value in the input image while it returns the same value for every positive value in the input image (for more in depth explanation of activation functions please check this [**article**](https://blog.goodaudience.com/artificial-neural-networks-explained-436fcf36e75) of mine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*6HyqifN4M_bJ7DTJ0RFRJA.jpeg)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the FC layer we flatten the output of the last Convolution layer and connect every node of the current layer with the other node of the next layer, Fully connected layer is just another word for the regular Artificial neural network as you will see in the image below.\n",
    "The operations in the fully connected layer are exactly the same as in any artificial neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = \\sigma(\\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*Zd5ScCO-meZl9yrCw6ZC0Q.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://image.slidesharecdn.com/styletemp-161002182243/95/deep-learning-behind-prisma-8-638.jpg?cb=1475432629)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers and operations discussed above are the core components of every Convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've discussed the operations that a ConvNet goes through in a forward pass let's jump to the operations that a ConvNet goes through in a backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the Fully connected layer backpropagation works exactly the same as in any regular artificial neural network, in backpropagation (using gradient descent as an optimization algorithm) we use partial derivatives namely the derivative of the loss function with regard to the weights $\\frac{\\partial J(\\theta_{i})}{\\partial \\theta_{i}}$, in order to calculate the latter we use a well known operation in calculus called **The Chain rule** where we multiply (in the backpropagation context) the derivative of the loss function w.r.t the activated output $\\frac{\\partial J(\\theta_{i})}{\\partial \\sigma(\\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b)}$  with the derivative of the activated output w.r.t the non-activated output $\\frac{\\partial \\sigma(\\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b)}{\\partial \\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b}$ with the derivative of the non-activated output w.r.t to the weights $\\frac{\\partial \\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b}{\\partial \\theta_{i}}$.\n",
    "$$ \\frac{\\partial J(\\theta_{i})}{\\partial \\theta_{i}} := \\frac{\\partial J(\\theta_{i})}{\\partial \\sigma(\\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b)} \\bullet \\frac{\\partial \\sigma(\\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b)}{\\partial \\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b} \\bullet \\frac{\\partial \\sum_{i=1}^{n} \\theta_{i}^{T} x_i + b}{\\partial \\theta_{i}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://matthewmazur.files.wordpress.com/2018/03/output_1_backprop-4.png?w=525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after calculating the gradient we substract it from the initial weights to get newly optimized ones:\n",
    "$$ \\theta_{i + 1} := \\theta_{i} - \\alpha \\nabla J(\\theta_{i}) $$\n",
    "where:\n",
    "- $ \\theta_{i + 1} :$ optimized weights\n",
    "- $ \\theta_{i} :$ initial weights\n",
    "- $ \\alpha :$ learning rates\n",
    "- $ \\nabla J(\\theta_{i}) :$ gradient of the loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/0*rBQI7uBhBKE8KT-X.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the animation below, gradient descent is applied to linear regression, you can clearly see that the more the cost function gets minimized the better the linear model fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imamdigmi.github.io/images/memahami-epoch-batch-size-iteration/gradient-descent.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that you should be careful with choosing the value of the learning rate, a very high learning rate could cause the gradient to overshoot the target minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/1600/0*QwE8M4MupSdqA3M4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all optimization tasks ,whether in physics, economics or Computer science, partial derivatives are overwhelmingly used, partial derivatives are primarily used to calculate the rate of change of a dependent variable $ f(x, y, z) $ with regard to one of its independent variables while the rest of the variables remain constant. for example imagine you own a share of a company, the stocks of the latter will go up or down based on multiple factors (security, politics, sales revenue etc ...), to implement partial derivatives on your situation you would calculate how much the stock price of your company change if security (for example) get affected while others factors remain constant and repeat the same process with each and every other factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Max Pooling layer the gradient gets backpropagated through the maximum values only since changing them slightly won't affect the output.\n",
    "In the process we replace the maximum values before max pooling with 1 and set all the non maximum values to zero then use the **Chain rule** to multiply the gradient by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/BackPropagation_MaxPool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the max pooling layer, in the average pooling layer the gradient passes through all the inputs (before average pooling) the maximum and the non maximum ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are probably asking yourself right now, if the forward pass of a convolution layer is a convolution then what is its backward pass ? luckily, its backward pass is also a convolution (as you can clearly see below) so you don't need to worry about learning new set of hard to grasp mathematical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/1000/1*CkzOyjui3ymVqF54BR6AOQ.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- $\\partial{h_{ij}}$: the derivative of the loss function w.r.t the output of the convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*VruqyvXfFMrFCa3E9U6Eog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in a nutshell how backpropagation works in a Convolution layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a robust theoretical understanding of Convolutional Neural Networks let's build our first ConvNet with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network with TensorFlow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensorflow ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/220px-TensorFlowLogo.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**TensorFlow**](https://opensource.com/article/17/11/intro-tensorflow) is an open source software library for numerical computation using data-flow graphs. It was originally developed by the Google Brain Team within Google's Machine Intelligence research organization for machine learning and deep neural networks research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Tensor ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [**tensor**](https://en.wikipedia.org/wiki/Tensor) is an organized multidimensional array of numerical values. The order (also degree or rank) of a tensor is the dimensionality of the array needed to represent it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/2000/1*_D5ZvufDS38WkhK9rK32hQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Computational Graph ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Computational graphs**](http://www.cs.columbia.edu/~mcollins/ff2.pdf) are a powerful formalism that have been extremely fruitful in deriving algorithms and software packages for neural networks and other models in machine learning. The basic idea in a computational graph is to express some model—for example a feedforward neural network—as a directed graph expressing a sequence of computational steps. Each step in the sequence corresponds to a vertex in the computational graph; each step corresponds to a simple operation that\n",
    "takes some inputs and produces some output as a function of its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the illustrated graph below we have two inputs $ w_{1} = x $ and $ w_{2} = y $, the inputs will flow through the graph where each node in the graph is a mathematical operation to give us the following outputs:\n",
    "- $ w_{3} = cos x $ where the operation is the Cosine trigonometric function\n",
    "- $ w_{4} = sin x $ where the operation is the Sine trigonometric function \n",
    "- $ w_{5} = w_{3} \\bullet w_{4} $ where the operation is multiplication \n",
    "- $ w_{6} = \\frac{w_{1}}{w_{2}} $ where the operation is division \n",
    "- $ w_{7} = w_{5} + w_{6} $ where the operation is addition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.columbia.edu/~ahd2125/static/img/2015-12-05/Fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand what a computational graph is, let's build our own in tensorflow, we will build the same one above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the deep learning library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define our compuational graph \n",
    "W1 = tf.constant(5.0, name = \"x\")\n",
    "W2 = tf.constant(3.0, name = \"y\")\n",
    "W3 = tf.cos(W1, name = \"cos\")\n",
    "W4 = tf.sin(W2, name = \"sin\")\n",
    "W5 = tf.multiply(W3, W4, name = \"mult\")\n",
    "W6 = tf.divide(W1, W2, name = \"div\")\n",
    "W7 = tf.add(W5, W6, name = \"add\")\n",
    "\n",
    "# Open the session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    cos = sess.run(W3)\n",
    "    sin = sess.run(W4)\n",
    "    mult = sess.run(W5)\n",
    "    div = sess.run(W6)\n",
    "    add = sess.run(W7)\n",
    "    \n",
    "    # Before running TensorBoard, make sure you have generated summary data in a log directory by creating a summary writer\n",
    "    writer = tf.summary.FileWriter(\"./Desktop/ComputationGraph\", sess.graph)\n",
    "    \n",
    "    # Once you have event files, run TensorBoard and provide the log directory\n",
    "    # Command: tensorboard --logdir=\"path/to/logs\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization with Tensorboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensorboard ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**TensorBoard**](https://github.com/tensorflow/tensorboard) is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs, it's one of the biggest edges that Google's TensorFlow has over Facebook's [**Pytorch**](https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*BIy_Sqob3hsC-oQkdd9UTg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a robust understanding of Convnets, TensorFlow and TensorBoard, let's build our first ConvNet that will recognize hand written digits using the **MNIST** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/b06741b45df8ffe29c7de999ab2ec4ff6b2965ba/687474703a2f2f6e657572616c6e6574776f726b73616e64646565706c6561726e696e672e636f6d2f696d616765732f6d6e6973745f3130305f6469676974732e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of our Convnet will be a set of convolution, max-pooling and non linearity layers similar to the [**LeNet-5**](http://yann.lecun.com/exdb/lenet/) architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://thumbs.gfycat.com/BonyTotalArthropods-size_restricted.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the deep learning library\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network inputs and outputs\n",
    "# The network's input is a 28×28 dimensional input\n",
    "n = 28\n",
    "m = 28\n",
    "num_input = n * m # MNIST data input \n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the parameters of our LeNET-5 inspired Convolutional Neural Network\n",
    "weights = {\n",
    "   \"W_ij\": tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "   \"W_jk\": tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "   \"W_kl\": tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "   \"W_lm\": tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "    }\n",
    "\n",
    "biases = {\n",
    "   \"b_ij\": tf.Variable(tf.random_normal([32])),\n",
    "   \"b_jk\": tf.Variable(tf.random_normal([64])),\n",
    "   \"b_kl\": tf.Variable(tf.random_normal([1024])),\n",
    "   \"b_lm\": tf.Variable(tf.random_normal([num_classes]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyper-parameters of our Convolutional Neural Network\n",
    "learning_rate = 1e-3\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvolutionLayer(x, W, b, strides=1):\n",
    "    # Convolution Layer\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    # ReLU activation function\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def PoolingLayer(x, k=2, strides=2):\n",
    "    # Max Pooling layer\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "def Softmax(x):\n",
    "    # Softmax activation function for the CNN's final output\n",
    "    return tf.nn.softmax(x)\n",
    "\n",
    "\n",
    "# Create model\n",
    "def ConvolutionalNeuralNetwork(x, weights, biases):\n",
    "    # MNIST data input is a 1-D row vector of 784 features (28×28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    Conv1 = ConvolutionLayer(x, weights[\"W_ij\"], biases[\"b_ij\"])\n",
    "    # Non-Linearity\n",
    "    ReLU1 = ReLU(Conv1)\n",
    "    # Max Pooling (down-sampling)\n",
    "    Pool1 = PoolingLayer(ReLU1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    Conv2 = ConvolutionLayer(Pool1, weights[\"W_jk\"], biases[\"b_jk\"])\n",
    "    # Non-Linearity\n",
    "    ReLU2 = ReLU(Conv2)\n",
    "    # Max Pooling (down-sampling)\n",
    "    Pool2 = PoolingLayer(ReLU2, k=2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    FC = tf.reshape(Pool2, [-1, weights[\"W_kl\"].get_shape().as_list()[0]])\n",
    "    FC = tf.add(tf.matmul(FC, weights[\"W_kl\"]), biases[\"b_kl\"])\n",
    "    FC = ReLU(FC)\n",
    "\n",
    "    # Output, class prediction\n",
    "    output = tf.add(tf.matmul(FC, weights[\"W_lm\"]), biases[\"b_lm\"])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = ConvolutionalNeuralNetwork(X, weights, biases)\n",
    "prediction = Softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softamx cross entropy loss function\n",
    "loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "# Optimization using the Adam Gradient Descent optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_process = optimizer.minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording how the loss functio varies over time during training\n",
    "cost = tf.summary.scalar(\"cost\", loss_function)\n",
    "training_accuracy = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "train_summary_op = tf.summary.merge([cost,training_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(\"./Desktop/logs\",\n",
    "                                        graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 74470.4844, Training Accuracy= 0.117\n",
      "Step 10, Minibatch Loss= 20529.4141, Training Accuracy= 0.250\n",
      "Step 20, Minibatch Loss= 14074.7539, Training Accuracy= 0.531\n",
      "Step 30, Minibatch Loss= 7168.9839, Training Accuracy= 0.586\n",
      "Step 40, Minibatch Loss= 4781.1060, Training Accuracy= 0.703\n",
      "Step 50, Minibatch Loss= 3281.0979, Training Accuracy= 0.766\n",
      "Step 60, Minibatch Loss= 2701.2451, Training Accuracy= 0.781\n",
      "Step 70, Minibatch Loss= 2478.7153, Training Accuracy= 0.773\n",
      "Step 80, Minibatch Loss= 2312.8320, Training Accuracy= 0.820\n",
      "Step 90, Minibatch Loss= 2143.0774, Training Accuracy= 0.852\n",
      "Step 100, Minibatch Loss= 1373.9169, Training Accuracy= 0.852\n",
      "Step 110, Minibatch Loss= 1852.9535, Training Accuracy= 0.852\n",
      "Step 120, Minibatch Loss= 1845.3500, Training Accuracy= 0.891\n",
      "Step 130, Minibatch Loss= 1677.2566, Training Accuracy= 0.844\n",
      "Step 140, Minibatch Loss= 1683.3661, Training Accuracy= 0.875\n",
      "Step 150, Minibatch Loss= 1859.3821, Training Accuracy= 0.836\n",
      "Step 160, Minibatch Loss= 1495.4796, Training Accuracy= 0.859\n",
      "Step 170, Minibatch Loss= 609.3800, Training Accuracy= 0.914\n",
      "Step 180, Minibatch Loss= 1376.5054, Training Accuracy= 0.891\n",
      "Step 190, Minibatch Loss= 1085.0363, Training Accuracy= 0.891\n",
      "Step 200, Minibatch Loss= 1129.7145, Training Accuracy= 0.914\n",
      "Step 210, Minibatch Loss= 1488.5452, Training Accuracy= 0.906\n",
      "Step 220, Minibatch Loss= 584.5027, Training Accuracy= 0.930\n",
      "Step 230, Minibatch Loss= 619.9744, Training Accuracy= 0.914\n",
      "Step 240, Minibatch Loss= 1575.8933, Training Accuracy= 0.891\n",
      "Step 250, Minibatch Loss= 1558.5853, Training Accuracy= 0.891\n",
      "Step 260, Minibatch Loss= 375.0371, Training Accuracy= 0.922\n",
      "Step 270, Minibatch Loss= 1568.0758, Training Accuracy= 0.859\n",
      "Step 280, Minibatch Loss= 1172.9205, Training Accuracy= 0.914\n",
      "Step 290, Minibatch Loss= 1023.5415, Training Accuracy= 0.914\n",
      "Step 300, Minibatch Loss= 475.9756, Training Accuracy= 0.945\n",
      "Step 310, Minibatch Loss= 488.8930, Training Accuracy= 0.961\n",
      "Step 320, Minibatch Loss= 1105.7720, Training Accuracy= 0.914\n",
      "Step 330, Minibatch Loss= 1111.8589, Training Accuracy= 0.906\n",
      "Step 340, Minibatch Loss= 842.7805, Training Accuracy= 0.930\n",
      "Step 350, Minibatch Loss= 1514.0153, Training Accuracy= 0.914\n",
      "Step 360, Minibatch Loss= 1722.1812, Training Accuracy= 0.875\n",
      "Step 370, Minibatch Loss= 681.6041, Training Accuracy= 0.891\n",
      "Step 380, Minibatch Loss= 902.8599, Training Accuracy= 0.930\n",
      "Step 390, Minibatch Loss= 714.1541, Training Accuracy= 0.930\n",
      "Step 400, Minibatch Loss= 1654.8883, Training Accuracy= 0.914\n",
      "Step 410, Minibatch Loss= 696.6915, Training Accuracy= 0.906\n",
      "Step 420, Minibatch Loss= 536.7183, Training Accuracy= 0.914\n",
      "Step 430, Minibatch Loss= 1405.9148, Training Accuracy= 0.891\n",
      "Step 440, Minibatch Loss= 199.4781, Training Accuracy= 0.953\n",
      "Step 450, Minibatch Loss= 438.3784, Training Accuracy= 0.938\n",
      "Step 460, Minibatch Loss= 409.6419, Training Accuracy= 0.969\n",
      "Step 470, Minibatch Loss= 503.1216, Training Accuracy= 0.930\n",
      "Step 480, Minibatch Loss= 482.6476, Training Accuracy= 0.922\n",
      "Step 490, Minibatch Loss= 767.3893, Training Accuracy= 0.922\n",
      "Step 500, Minibatch Loss= 626.8249, Training Accuracy= 0.930\n",
      "Time duration: 657 seconds\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9453125\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(training_process, feed_dict={X: batch_x, Y: batch_y})\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc, summary = sess.run([loss_function, accuracy, train_summary_op], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            train_writer.add_summary(summary, step)\n",
    "            \n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    end_time = time.time() \n",
    "    \n",
    "    print(\"Time duration: \" + str(int(end_time-start_time)) + \" seconds\")\n",
    "    print(\"Optimization Finished!\")\n",
    "            \n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just finished building our first convolutional neural network, as you can see in the results above, the accuracy has dramatically increased from the first step to the last step, but still there is more room for improvement of our ConNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now visualize our ConvNet in Tensorboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/1000/1*IG7juGoP2xRsyEZP8hA6hA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*qfK6YdI0miD3wNhwrhISGA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks are powerful deep learning models that are applied in a wide range of fields such as radiology, the use of ConvNets will only increase as the data gets bigger and the problems become more sophisticated and challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
    "- https://en.wikipedia.org/wiki/Yann_LeCun\n",
    "- http://yann.lecun.com/exdb/mnist/\n",
    "- https://opensource.com/article/17/11/intro-tensorflow\n",
    "- https://en.wikipedia.org/wiki/Tensor\n",
    "- http://www.cs.columbia.edu/~mcollins/ff2.pdf\n",
    "- https://github.com/tensorflow/tensorboard\n",
    "- http://yann.lecun.com/exdb/lenet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
